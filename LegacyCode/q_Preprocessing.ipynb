{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_path='data/eaglei_data/'\n",
    "storm_path='data/NOAA_StormEvents/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_code</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>customers_out</th>\n",
       "      <th>run_start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021</td>\n",
       "      <td>Chilton</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5003</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5023</td>\n",
       "      <td>Cleburne</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5085</td>\n",
       "      <td>Lonoke</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5107</td>\n",
       "      <td>Phillips</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12939152</th>\n",
       "      <td>55059</td>\n",
       "      <td>Kenosha</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12939153</th>\n",
       "      <td>55079</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12939154</th>\n",
       "      <td>55097</td>\n",
       "      <td>Portage</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12939155</th>\n",
       "      <td>55117</td>\n",
       "      <td>Sheboygan</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>166</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12939156</th>\n",
       "      <td>55127</td>\n",
       "      <td>Walworth</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12939157 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fips_code     county      state  customers_out       run_start_time\n",
       "0              1021    Chilton    Alabama              3  2015-01-01 00:00:00\n",
       "1              5003     Ashley   Arkansas              3  2015-01-01 00:00:00\n",
       "2              5023   Cleburne   Arkansas              1  2015-01-01 00:00:00\n",
       "3              5085     Lonoke   Arkansas              2  2015-01-01 00:00:00\n",
       "4              5107   Phillips   Arkansas              3  2015-01-01 00:00:00\n",
       "...             ...        ...        ...            ...                  ...\n",
       "12939152      55059    Kenosha  Wisconsin              1  2015-12-31 00:00:00\n",
       "12939153      55079  Milwaukee  Wisconsin              1  2015-12-31 00:00:00\n",
       "12939154      55097    Portage  Wisconsin              1  2015-12-31 00:00:00\n",
       "12939155      55117  Sheboygan  Wisconsin            166  2015-12-31 00:00:00\n",
       "12939156      55127   Walworth  Wisconsin              1  2015-12-31 00:00:00\n",
       "\n",
       "[12939157 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eaglei_2015=pd.read_csv(elec_path+'eaglei_outages_2015.csv')\n",
    "eaglei_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_customers_out_by_date(df):\n",
    "    \"\"\"\n",
    "    Group the DataFrame by county, state, and the date part of run_start_time, \n",
    "    and sum the customers_out values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Original data containing columns \n",
    "            ['fips_code', 'county', 'state', 'customers_out', 'run_start_time'].\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Grouped data with columns \n",
    "            ['county', 'state', 'date', 'customers_out', 'run_start_time'].\n",
    "    \"\"\"\n",
    "    # Make a copy of the DataFrame to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure 'run_start_time' is of datetime type\n",
    "    df['run_start_time'] = pd.to_datetime(df['run_start_time'])\n",
    "\n",
    "    # Extract the date part only\n",
    "    df['date'] = df['run_start_time'].dt.date\n",
    "\n",
    "    # Group by county, state, and date, and sum the customers_out\n",
    "    grouped = df.groupby(['fips_code', 'date']).agg({\n",
    "        'customers_out': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Add back a datetime version of the date if needed\n",
    "    grouped['run_start_time'] = pd.to_datetime(grouped['date'])\n",
    "\n",
    "    return grouped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_code</th>\n",
       "      <th>date</th>\n",
       "      <th>customers_out</th>\n",
       "      <th>run_start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>21</td>\n",
       "      <td>2015-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>25</td>\n",
       "      <td>2015-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>24</td>\n",
       "      <td>2015-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485523</th>\n",
       "      <td>56029</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>1950</td>\n",
       "      <td>2015-04-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485524</th>\n",
       "      <td>56029</td>\n",
       "      <td>2015-04-24</td>\n",
       "      <td>10075</td>\n",
       "      <td>2015-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485525</th>\n",
       "      <td>56029</td>\n",
       "      <td>2015-05-06</td>\n",
       "      <td>2275</td>\n",
       "      <td>2015-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485526</th>\n",
       "      <td>56029</td>\n",
       "      <td>2015-05-16</td>\n",
       "      <td>5868</td>\n",
       "      <td>2015-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485527</th>\n",
       "      <td>56029</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>981</td>\n",
       "      <td>2015-06-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485528 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fips_code        date  customers_out run_start_time\n",
       "0            1001  2015-01-04             21     2015-01-04\n",
       "1            1001  2015-01-05              2     2015-01-05\n",
       "2            1001  2015-01-06             25     2015-01-06\n",
       "3            1001  2015-01-08             24     2015-01-08\n",
       "4            1001  2015-01-09              2     2015-01-09\n",
       "...           ...         ...            ...            ...\n",
       "485523      56029  2015-04-23           1950     2015-04-23\n",
       "485524      56029  2015-04-24          10075     2015-04-24\n",
       "485525      56029  2015-05-06           2275     2015-05-06\n",
       "485526      56029  2015-05-16           5868     2015-05-16\n",
       "485527      56029  2015-06-02            981     2015-06-02\n",
       "\n",
       "[485528 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_example=group_customers_out_by_date(eaglei_2015)\n",
    "df_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Storms=pd.read_csv(storm_path+'StormEvents_details-ftp_v1.0_d2015_c20240716.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/n1hnl_j93_d4b92q_jxc8rz80000gn/T/ipykernel_61860/2862265501.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_storm['BEGIN_DATE_TIME'] = pd.to_datetime(df_storm['BEGIN_DATE_TIME']).dt.date\n",
      "/var/folders/02/n1hnl_j93_d4b92q_jxc8rz80000gn/T/ipykernel_61860/2862265501.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_storm['END_DATE_TIME'] = pd.to_datetime(df_storm['END_DATE_TIME']).dt.date\n"
     ]
    }
   ],
   "source": [
    "def change_date_storm(df_storm):\n",
    "    df_storm['BEGIN_DATE_TIME'] = pd.to_datetime(df_storm['BEGIN_DATE_TIME']).dt.date\n",
    "    df_storm['END_DATE_TIME'] = pd.to_datetime(df_storm['END_DATE_TIME']).dt.date\n",
    "    return df_storm\n",
    "df_storm=change_date_storm(Storms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/n1hnl_j93_d4b92q_jxc8rz80000gn/T/ipykernel_61860/2339681555.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  storms['STATE_FIPS'] = storms['STATE_FIPS'].astype(str).str.zfill(2)\n",
      "/var/folders/02/n1hnl_j93_d4b92q_jxc8rz80000gn/T/ipykernel_61860/2339681555.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  storms['CZ_FIPS'] = storms['CZ_FIPS'].astype(str).str.zfill(3)\n",
      "/var/folders/02/n1hnl_j93_d4b92q_jxc8rz80000gn/T/ipykernel_61860/2339681555.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  storms['FIPS'] = storms['STATE_FIPS'] + storms['CZ_FIPS']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "      <th>FIPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201509</td>\n",
       "      <td>5</td>\n",
       "      <td>1418</td>\n",
       "      <td>201509</td>\n",
       "      <td>5</td>\n",
       "      <td>1422</td>\n",
       "      <td>98915</td>\n",
       "      <td>594085</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NE</td>\n",
       "      <td>MAGRUDER</td>\n",
       "      <td>32.9400</td>\n",
       "      <td>-82.2000</td>\n",
       "      <td>32.9400</td>\n",
       "      <td>-82.2000</td>\n",
       "      <td>Some thunderstorms in the CSRA took down sever...</td>\n",
       "      <td>Sheriff reported trees down on Hickson Road.</td>\n",
       "      <td>CSV</td>\n",
       "      <td>13033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201509</td>\n",
       "      <td>10</td>\n",
       "      <td>1628</td>\n",
       "      <td>201509</td>\n",
       "      <td>10</td>\n",
       "      <td>1632</td>\n",
       "      <td>98918</td>\n",
       "      <td>594086</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>ELGIN</td>\n",
       "      <td>34.7100</td>\n",
       "      <td>-80.7200</td>\n",
       "      <td>34.7100</td>\n",
       "      <td>-80.7200</td>\n",
       "      <td>A few thunderstorms in the Eastern Midlands pr...</td>\n",
       "      <td>Dispatch reported straight line wind damage, i...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>45057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201509</td>\n",
       "      <td>4</td>\n",
       "      <td>1440</td>\n",
       "      <td>201509</td>\n",
       "      <td>4</td>\n",
       "      <td>1444</td>\n",
       "      <td>98915</td>\n",
       "      <td>594083</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>ENE</td>\n",
       "      <td>MAGRUDER</td>\n",
       "      <td>32.9400</td>\n",
       "      <td>-82.1400</td>\n",
       "      <td>32.9400</td>\n",
       "      <td>-82.1400</td>\n",
       "      <td>Some thunderstorms in the CSRA took down sever...</td>\n",
       "      <td>Public reported a few small trees and large li...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>13033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>201509</td>\n",
       "      <td>5</td>\n",
       "      <td>1417</td>\n",
       "      <td>201509</td>\n",
       "      <td>5</td>\n",
       "      <td>1421</td>\n",
       "      <td>98915</td>\n",
       "      <td>594084</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>ESE</td>\n",
       "      <td>KEYSVILLE</td>\n",
       "      <td>33.2100</td>\n",
       "      <td>-82.1500</td>\n",
       "      <td>33.2100</td>\n",
       "      <td>-82.1500</td>\n",
       "      <td>Some thunderstorms in the CSRA took down sever...</td>\n",
       "      <td>Sheriff reported trees down on George Perkins ...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>13033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>201509</td>\n",
       "      <td>10</td>\n",
       "      <td>1628</td>\n",
       "      <td>201509</td>\n",
       "      <td>10</td>\n",
       "      <td>1632</td>\n",
       "      <td>98918</td>\n",
       "      <td>594087</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>LANCASTER</td>\n",
       "      <td>34.7200</td>\n",
       "      <td>-80.7500</td>\n",
       "      <td>34.7200</td>\n",
       "      <td>-80.7500</td>\n",
       "      <td>A few thunderstorms in the Eastern Midlands pr...</td>\n",
       "      <td>Dispatch reported a large carport and shed blo...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>45057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57901</th>\n",
       "      <td>201512</td>\n",
       "      <td>25</td>\n",
       "      <td>1525</td>\n",
       "      <td>201512</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>101375</td>\n",
       "      <td>609959</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>HOLMES GAP</td>\n",
       "      <td>34.2331</td>\n",
       "      <td>-86.8490</td>\n",
       "      <td>34.2243</td>\n",
       "      <td>-86.8498</td>\n",
       "      <td>Numerous systems affecting the Tennessee valle...</td>\n",
       "      <td>Water completely covering the bridge over Lake...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>01043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57902</th>\n",
       "      <td>201512</td>\n",
       "      <td>25</td>\n",
       "      <td>1035</td>\n",
       "      <td>201512</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>102024</td>\n",
       "      <td>610100</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>SE</td>\n",
       "      <td>WINCHESTER SPGS</td>\n",
       "      <td>35.2214</td>\n",
       "      <td>-86.1436</td>\n",
       "      <td>35.2131</td>\n",
       "      <td>-86.1441</td>\n",
       "      <td>Numerous systems affecting the Tennessee valle...</td>\n",
       "      <td>Eight inches of water over Old Estill Springs ...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>47051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57903</th>\n",
       "      <td>201512</td>\n",
       "      <td>25</td>\n",
       "      <td>2215</td>\n",
       "      <td>201512</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>101375</td>\n",
       "      <td>609689</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>ENE</td>\n",
       "      <td>CENTERVILLE</td>\n",
       "      <td>34.2835</td>\n",
       "      <td>-86.9144</td>\n",
       "      <td>34.2835</td>\n",
       "      <td>-86.9144</td>\n",
       "      <td>Numerous systems affecting the Tennessee valle...</td>\n",
       "      <td>Rainfall total as of 7:15pm observation: 10.79...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>01043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57904</th>\n",
       "      <td>201512</td>\n",
       "      <td>23</td>\n",
       "      <td>1900</td>\n",
       "      <td>201512</td>\n",
       "      <td>23</td>\n",
       "      <td>1908</td>\n",
       "      <td>101367</td>\n",
       "      <td>606485</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>WNW</td>\n",
       "      <td>MURPHY XRDS</td>\n",
       "      <td>34.9540</td>\n",
       "      <td>-88.0731</td>\n",
       "      <td>35.0060</td>\n",
       "      <td>-87.9580</td>\n",
       "      <td>A potent low pressure lifted from the central ...</td>\n",
       "      <td>A tornado touched down initially near the inte...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>01077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57906</th>\n",
       "      <td>201512</td>\n",
       "      <td>23</td>\n",
       "      <td>1817</td>\n",
       "      <td>201512</td>\n",
       "      <td>23</td>\n",
       "      <td>1827</td>\n",
       "      <td>101491</td>\n",
       "      <td>607144</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>CHESTNUT GROVE</td>\n",
       "      <td>35.5499</td>\n",
       "      <td>-87.8145</td>\n",
       "      <td>35.6186</td>\n",
       "      <td>-87.6676</td>\n",
       "      <td>An unusually powerful upper level trough moved...</td>\n",
       "      <td>An EF2 tornado touched down in southern Perry ...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>47135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35116 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  \\\n",
       "6               201509          5        1418         201509        5   \n",
       "7               201509         10        1628         201509       10   \n",
       "8               201509          4        1440         201509        4   \n",
       "9               201509          5        1417         201509        5   \n",
       "10              201509         10        1628         201509       10   \n",
       "...                ...        ...         ...            ...      ...   \n",
       "57901           201512         25        1525         201512       26   \n",
       "57902           201512         25        1035         201512       26   \n",
       "57903           201512         25        2215         201512       26   \n",
       "57904           201512         23        1900         201512       23   \n",
       "57906           201512         23        1817         201512       23   \n",
       "\n",
       "       END_TIME  EPISODE_ID  EVENT_ID           STATE STATE_FIPS  ...  \\\n",
       "6          1422       98915    594085         GEORGIA         13  ...   \n",
       "7          1632       98918    594086  SOUTH CAROLINA         45  ...   \n",
       "8          1444       98915    594083         GEORGIA         13  ...   \n",
       "9          1421       98915    594084         GEORGIA         13  ...   \n",
       "10         1632       98918    594087  SOUTH CAROLINA         45  ...   \n",
       "...         ...         ...       ...             ...        ...  ...   \n",
       "57901         0      101375    609959         ALABAMA         01  ...   \n",
       "57902         0      102024    610100       TENNESSEE         47  ...   \n",
       "57903         0      101375    609689         ALABAMA         01  ...   \n",
       "57904      1908      101367    606485         ALABAMA         01  ...   \n",
       "57906      1827      101491    607144       TENNESSEE         47  ...   \n",
       "\n",
       "       END_AZIMUTH     END_LOCATION BEGIN_LAT BEGIN_LON  END_LAT  END_LON  \\\n",
       "6               NE         MAGRUDER   32.9400  -82.2000  32.9400 -82.2000   \n",
       "7                N            ELGIN   34.7100  -80.7200  34.7100 -80.7200   \n",
       "8              ENE         MAGRUDER   32.9400  -82.1400  32.9400 -82.1400   \n",
       "9              ESE        KEYSVILLE   33.2100  -82.1500  33.2100 -82.1500   \n",
       "10               E        LANCASTER   34.7200  -80.7500  34.7200 -80.7500   \n",
       "...            ...              ...       ...       ...      ...      ...   \n",
       "57901            S       HOLMES GAP   34.2331  -86.8490  34.2243 -86.8498   \n",
       "57902           SE  WINCHESTER SPGS   35.2214  -86.1436  35.2131 -86.1441   \n",
       "57903          ENE      CENTERVILLE   34.2835  -86.9144  34.2835 -86.9144   \n",
       "57904          WNW      MURPHY XRDS   34.9540  -88.0731  35.0060 -87.9580   \n",
       "57906            E   CHESTNUT GROVE   35.5499  -87.8145  35.6186 -87.6676   \n",
       "\n",
       "                                       EPISODE_NARRATIVE  \\\n",
       "6      Some thunderstorms in the CSRA took down sever...   \n",
       "7      A few thunderstorms in the Eastern Midlands pr...   \n",
       "8      Some thunderstorms in the CSRA took down sever...   \n",
       "9      Some thunderstorms in the CSRA took down sever...   \n",
       "10     A few thunderstorms in the Eastern Midlands pr...   \n",
       "...                                                  ...   \n",
       "57901  Numerous systems affecting the Tennessee valle...   \n",
       "57902  Numerous systems affecting the Tennessee valle...   \n",
       "57903  Numerous systems affecting the Tennessee valle...   \n",
       "57904  A potent low pressure lifted from the central ...   \n",
       "57906  An unusually powerful upper level trough moved...   \n",
       "\n",
       "                                         EVENT_NARRATIVE DATA_SOURCE   FIPS  \n",
       "6           Sheriff reported trees down on Hickson Road.         CSV  13033  \n",
       "7      Dispatch reported straight line wind damage, i...         CSV  45057  \n",
       "8      Public reported a few small trees and large li...         CSV  13033  \n",
       "9      Sheriff reported trees down on George Perkins ...         CSV  13033  \n",
       "10     Dispatch reported a large carport and shed blo...         CSV  45057  \n",
       "...                                                  ...         ...    ...  \n",
       "57901  Water completely covering the bridge over Lake...         CSV  01043  \n",
       "57902  Eight inches of water over Old Estill Springs ...         CSV  47051  \n",
       "57903  Rainfall total as of 7:15pm observation: 10.79...         CSV  01043  \n",
       "57904  A tornado touched down initially near the inte...         CSV  01077  \n",
       "57906  An EF2 tornado touched down in southern Perry ...         CSV  47135  \n",
       "\n",
       "[35116 rows x 52 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def keep_c_storm(df_storm):\n",
    "    df_storm = df_storm[df_storm['CZ_TYPE'] == 'C']\n",
    "    return df_storm\n",
    "\n",
    "def make_fips_storm(storms):\n",
    "    storms['STATE_FIPS'] = storms['STATE_FIPS'].astype(str).str.zfill(2)\n",
    "    storms['CZ_FIPS'] = storms['CZ_FIPS'].astype(str).str.zfill(3)\n",
    "    storms['FIPS'] = storms['STATE_FIPS'] + storms['CZ_FIPS']\n",
    "    return storms\n",
    "\n",
    "df_storm=keep_c_storm(df_storm)\n",
    "df_storm=make_fips_storm(df_storm)\n",
    "df_storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating customers_out: 100%|██████████| 485528/485528 [05:21<00:00, 1510.92it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# def update_customers_out(df_storm, df_example):\n",
    "#     \"\"\"\n",
    "#     Update the 'customers_out' column in df_storm based on matching time intervals \n",
    "#     and FIPS codes from df_example.\n",
    "\n",
    "#     Args:\n",
    "#         df_storm (pd.DataFrame): DataFrame containing storm events with columns \n",
    "#             ['FIPS', 'BEGIN_DATE_TIME', 'END_DATE_TIME', ...].\n",
    "#         df_example (pd.DataFrame): DataFrame containing customer outage events with columns \n",
    "#             ['fips_code', 'customers_out', 'run_start_time', ...].\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: Updated df_storm with the 'customers_out' column modified.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Ensure correct data types\n",
    "#     df_storm = df_storm.copy()\n",
    "#     df_storm['FIPS'] = df_storm['FIPS'].astype('int64')\n",
    "#     df_storm['BEGIN_DATE_TIME'] = pd.to_datetime(df_storm['BEGIN_DATE_TIME'])\n",
    "#     df_storm['END_DATE_TIME'] = pd.to_datetime(df_storm['END_DATE_TIME'])\n",
    "    \n",
    "#     df_example = df_example.copy()\n",
    "#     df_example['run_start_time'] = pd.to_datetime(df_example['run_start_time'])\n",
    "\n",
    "#     # Initialize the customers_out column if it does not exist\n",
    "#     if 'customers_out' not in df_storm.columns:\n",
    "#         df_storm['customers_out'] = 0\n",
    "\n",
    "#     # Iterate over each row in df_example\n",
    "#     for idx, row in tqdm(df_example.iterrows(), total=len(df_example), desc=\"Updating customers_out\"):\n",
    "#         run_time = row['run_start_time']\n",
    "#         customers_out_value = row['customers_out']\n",
    "#         fips_code = row['fips_code']\n",
    "\n",
    "#         # Create a mask to find matching storm records\n",
    "#         mask = (\n",
    "#             (df_storm['BEGIN_DATE_TIME'] <= run_time) & \n",
    "#             (df_storm['END_DATE_TIME'] >= run_time) & \n",
    "#             (df_storm['FIPS'] == fips_code)\n",
    "#         )\n",
    "\n",
    "#         # Add customers_out_value to matched rows\n",
    "#         df_storm.loc[mask, 'customers_out'] += customers_out_value\n",
    "\n",
    "#     return df_storm\n",
    "\n",
    "\n",
    "def update_customers_out(df_storm, df_example):\n",
    "    \"\"\"\n",
    "    Update the 'customers_out' column in df_storm based on matching time intervals \n",
    "    and FIPS codes from df_example, and store an array of run_start_time values \n",
    "    for matching outage events.\n",
    "\n",
    "    Args:\n",
    "        df_storm (pd.DataFrame): DataFrame containing storm events with columns \n",
    "            ['FIPS', 'BEGIN_DATE_TIME', 'END_DATE_TIME', ...].\n",
    "        df_example (pd.DataFrame): DataFrame containing customer outage events with columns \n",
    "            ['fips_code', 'customers_out', 'run_start_time', ...].\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated df_storm with 'customers_out' and 'run_start_times' columns modified.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure correct data types\n",
    "    df_storm = df_storm.copy()\n",
    "    df_storm['FIPS'] = df_storm['FIPS'].astype('int64')\n",
    "    df_storm['BEGIN_DATE_TIME'] = pd.to_datetime(df_storm['BEGIN_DATE_TIME'])\n",
    "    df_storm['END_DATE_TIME'] = pd.to_datetime(df_storm['END_DATE_TIME'])\n",
    "    \n",
    "    df_example = df_example.copy()\n",
    "    df_example['run_start_time'] = pd.to_datetime(df_example['run_start_time'])\n",
    "    df_example['fips_code'] = df_example['fips_code'].astype('int64')\n",
    "\n",
    "    # Initialize columns if they do not exist\n",
    "    if 'customers_out' not in df_storm.columns:\n",
    "        df_storm['customers_out'] = 0\n",
    "    if 'run_start_times' not in df_storm.columns:\n",
    "        df_storm['run_start_times'] = [[] for _ in range(len(df_storm))]\n",
    "\n",
    "    # Iterate over each row in df_example\n",
    "    for idx, row in tqdm(df_example.iterrows(), total=len(df_example), desc=\"Updating customers_out\"):\n",
    "        run_time = row['run_start_time']\n",
    "        customers_out_value = row['customers_out']\n",
    "        fips_code = row['fips_code']\n",
    "\n",
    "        # Create a mask to find matching storm records\n",
    "        mask = (\n",
    "            (df_storm['BEGIN_DATE_TIME'] <= run_time) & \n",
    "            (df_storm['END_DATE_TIME'] >= run_time) & \n",
    "            (df_storm['FIPS'] == fips_code)\n",
    "        )\n",
    "\n",
    "        # Update customers_out and append run_start_time to the list\n",
    "        df_storm.loc[mask, 'customers_out'] += customers_out_value\n",
    "        df_storm.loc[mask, 'run_start_times'] = df_storm.loc[mask, 'run_start_times'].apply(\n",
    "            lambda x: x + [run_time]\n",
    "        )\n",
    "\n",
    "    return df_storm\n",
    "\n",
    "\n",
    "df_storm=update_customers_out(df_storm, df_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_lead_time_column(df_storm):\n",
    "    \"\"\"\n",
    "    Add a 'lead_time' column to df_storm, containing a list of time differences (in hours)\n",
    "    between each run_start_time and BEGIN_DATE_TIME. If run_start_times is empty, set lead_time to 0.\n",
    "\n",
    "    Args:\n",
    "        df_storm (pd.DataFrame): DataFrame with columns ['BEGIN_DATE_TIME', 'run_start_times', ...].\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated df_storm with a new 'lead_time' column.\n",
    "    \"\"\"\n",
    "    # Ensure df_storm is a copy to avoid modifying the input\n",
    "    df_storm = df_storm.copy()\n",
    "\n",
    "    # Initialize the lead_time column\n",
    "    df_storm['lead_time'] = df_storm.apply(\n",
    "        lambda row: [\n",
    "            (run_time - row['BEGIN_DATE_TIME']).total_seconds() / 86400  # Convert to hours\n",
    "            for run_time in row['run_start_times']\n",
    "        ] if row['run_start_times'] else [-1.0],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return df_storm\n",
    "\n",
    "df_storm_updated = add_lead_time_column(df_storm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>customers_out</th>\n",
       "      <th>run_start_times</th>\n",
       "      <th>lead_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201509</td>\n",
       "      <td>5</td>\n",
       "      <td>1418</td>\n",
       "      <td>201509</td>\n",
       "      <td>5</td>\n",
       "      <td>1422</td>\n",
       "      <td>98915</td>\n",
       "      <td>594085</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.2000</td>\n",
       "      <td>32.9400</td>\n",
       "      <td>-82.2000</td>\n",
       "      <td>Some thunderstorms in the CSRA took down sever...</td>\n",
       "      <td>Sheriff reported trees down on Hickson Road.</td>\n",
       "      <td>CSV</td>\n",
       "      <td>13033</td>\n",
       "      <td>271</td>\n",
       "      <td>[2015-09-05 00:00:00]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201509</td>\n",
       "      <td>10</td>\n",
       "      <td>1628</td>\n",
       "      <td>201509</td>\n",
       "      <td>10</td>\n",
       "      <td>1632</td>\n",
       "      <td>98918</td>\n",
       "      <td>594086</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>-80.7200</td>\n",
       "      <td>34.7100</td>\n",
       "      <td>-80.7200</td>\n",
       "      <td>A few thunderstorms in the Eastern Midlands pr...</td>\n",
       "      <td>Dispatch reported straight line wind damage, i...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>45057</td>\n",
       "      <td>1397</td>\n",
       "      <td>[2015-09-10 00:00:00]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201509</td>\n",
       "      <td>4</td>\n",
       "      <td>1440</td>\n",
       "      <td>201509</td>\n",
       "      <td>4</td>\n",
       "      <td>1444</td>\n",
       "      <td>98915</td>\n",
       "      <td>594083</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.1400</td>\n",
       "      <td>32.9400</td>\n",
       "      <td>-82.1400</td>\n",
       "      <td>Some thunderstorms in the CSRA took down sever...</td>\n",
       "      <td>Public reported a few small trees and large li...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>13033</td>\n",
       "      <td>621</td>\n",
       "      <td>[2015-09-04 00:00:00]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>201509</td>\n",
       "      <td>5</td>\n",
       "      <td>1417</td>\n",
       "      <td>201509</td>\n",
       "      <td>5</td>\n",
       "      <td>1421</td>\n",
       "      <td>98915</td>\n",
       "      <td>594084</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.1500</td>\n",
       "      <td>33.2100</td>\n",
       "      <td>-82.1500</td>\n",
       "      <td>Some thunderstorms in the CSRA took down sever...</td>\n",
       "      <td>Sheriff reported trees down on George Perkins ...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>13033</td>\n",
       "      <td>271</td>\n",
       "      <td>[2015-09-05 00:00:00]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>201509</td>\n",
       "      <td>10</td>\n",
       "      <td>1628</td>\n",
       "      <td>201509</td>\n",
       "      <td>10</td>\n",
       "      <td>1632</td>\n",
       "      <td>98918</td>\n",
       "      <td>594087</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>-80.7500</td>\n",
       "      <td>34.7200</td>\n",
       "      <td>-80.7500</td>\n",
       "      <td>A few thunderstorms in the Eastern Midlands pr...</td>\n",
       "      <td>Dispatch reported a large carport and shed blo...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>45057</td>\n",
       "      <td>1397</td>\n",
       "      <td>[2015-09-10 00:00:00]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57901</th>\n",
       "      <td>201512</td>\n",
       "      <td>25</td>\n",
       "      <td>1525</td>\n",
       "      <td>201512</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>101375</td>\n",
       "      <td>609959</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>-86.8490</td>\n",
       "      <td>34.2243</td>\n",
       "      <td>-86.8498</td>\n",
       "      <td>Numerous systems affecting the Tennessee valle...</td>\n",
       "      <td>Water completely covering the bridge over Lake...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>1043</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57902</th>\n",
       "      <td>201512</td>\n",
       "      <td>25</td>\n",
       "      <td>1035</td>\n",
       "      <td>201512</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>102024</td>\n",
       "      <td>610100</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>-86.1436</td>\n",
       "      <td>35.2131</td>\n",
       "      <td>-86.1441</td>\n",
       "      <td>Numerous systems affecting the Tennessee valle...</td>\n",
       "      <td>Eight inches of water over Old Estill Springs ...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>47051</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57903</th>\n",
       "      <td>201512</td>\n",
       "      <td>25</td>\n",
       "      <td>2215</td>\n",
       "      <td>201512</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>101375</td>\n",
       "      <td>609689</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>-86.9144</td>\n",
       "      <td>34.2835</td>\n",
       "      <td>-86.9144</td>\n",
       "      <td>Numerous systems affecting the Tennessee valle...</td>\n",
       "      <td>Rainfall total as of 7:15pm observation: 10.79...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>1043</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57904</th>\n",
       "      <td>201512</td>\n",
       "      <td>23</td>\n",
       "      <td>1900</td>\n",
       "      <td>201512</td>\n",
       "      <td>23</td>\n",
       "      <td>1908</td>\n",
       "      <td>101367</td>\n",
       "      <td>606485</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>-88.0731</td>\n",
       "      <td>35.0060</td>\n",
       "      <td>-87.9580</td>\n",
       "      <td>A potent low pressure lifted from the central ...</td>\n",
       "      <td>A tornado touched down initially near the inte...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>1077</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57906</th>\n",
       "      <td>201512</td>\n",
       "      <td>23</td>\n",
       "      <td>1817</td>\n",
       "      <td>201512</td>\n",
       "      <td>23</td>\n",
       "      <td>1827</td>\n",
       "      <td>101491</td>\n",
       "      <td>607144</td>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.8145</td>\n",
       "      <td>35.6186</td>\n",
       "      <td>-87.6676</td>\n",
       "      <td>An unusually powerful upper level trough moved...</td>\n",
       "      <td>An EF2 tornado touched down in southern Perry ...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>47135</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35116 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  \\\n",
       "6               201509          5        1418         201509        5   \n",
       "7               201509         10        1628         201509       10   \n",
       "8               201509          4        1440         201509        4   \n",
       "9               201509          5        1417         201509        5   \n",
       "10              201509         10        1628         201509       10   \n",
       "...                ...        ...         ...            ...      ...   \n",
       "57901           201512         25        1525         201512       26   \n",
       "57902           201512         25        1035         201512       26   \n",
       "57903           201512         25        2215         201512       26   \n",
       "57904           201512         23        1900         201512       23   \n",
       "57906           201512         23        1817         201512       23   \n",
       "\n",
       "       END_TIME  EPISODE_ID  EVENT_ID           STATE STATE_FIPS  ...  \\\n",
       "6          1422       98915    594085         GEORGIA         13  ...   \n",
       "7          1632       98918    594086  SOUTH CAROLINA         45  ...   \n",
       "8          1444       98915    594083         GEORGIA         13  ...   \n",
       "9          1421       98915    594084         GEORGIA         13  ...   \n",
       "10         1632       98918    594087  SOUTH CAROLINA         45  ...   \n",
       "...         ...         ...       ...             ...        ...  ...   \n",
       "57901         0      101375    609959         ALABAMA         01  ...   \n",
       "57902         0      102024    610100       TENNESSEE         47  ...   \n",
       "57903         0      101375    609689         ALABAMA         01  ...   \n",
       "57904      1908      101367    606485         ALABAMA         01  ...   \n",
       "57906      1827      101491    607144       TENNESSEE         47  ...   \n",
       "\n",
       "       BEGIN_LON  END_LAT  END_LON  \\\n",
       "6       -82.2000  32.9400 -82.2000   \n",
       "7       -80.7200  34.7100 -80.7200   \n",
       "8       -82.1400  32.9400 -82.1400   \n",
       "9       -82.1500  33.2100 -82.1500   \n",
       "10      -80.7500  34.7200 -80.7500   \n",
       "...          ...      ...      ...   \n",
       "57901   -86.8490  34.2243 -86.8498   \n",
       "57902   -86.1436  35.2131 -86.1441   \n",
       "57903   -86.9144  34.2835 -86.9144   \n",
       "57904   -88.0731  35.0060 -87.9580   \n",
       "57906   -87.8145  35.6186 -87.6676   \n",
       "\n",
       "                                       EPISODE_NARRATIVE  \\\n",
       "6      Some thunderstorms in the CSRA took down sever...   \n",
       "7      A few thunderstorms in the Eastern Midlands pr...   \n",
       "8      Some thunderstorms in the CSRA took down sever...   \n",
       "9      Some thunderstorms in the CSRA took down sever...   \n",
       "10     A few thunderstorms in the Eastern Midlands pr...   \n",
       "...                                                  ...   \n",
       "57901  Numerous systems affecting the Tennessee valle...   \n",
       "57902  Numerous systems affecting the Tennessee valle...   \n",
       "57903  Numerous systems affecting the Tennessee valle...   \n",
       "57904  A potent low pressure lifted from the central ...   \n",
       "57906  An unusually powerful upper level trough moved...   \n",
       "\n",
       "                                         EVENT_NARRATIVE DATA_SOURCE   FIPS  \\\n",
       "6           Sheriff reported trees down on Hickson Road.         CSV  13033   \n",
       "7      Dispatch reported straight line wind damage, i...         CSV  45057   \n",
       "8      Public reported a few small trees and large li...         CSV  13033   \n",
       "9      Sheriff reported trees down on George Perkins ...         CSV  13033   \n",
       "10     Dispatch reported a large carport and shed blo...         CSV  45057   \n",
       "...                                                  ...         ...    ...   \n",
       "57901  Water completely covering the bridge over Lake...         CSV   1043   \n",
       "57902  Eight inches of water over Old Estill Springs ...         CSV  47051   \n",
       "57903  Rainfall total as of 7:15pm observation: 10.79...         CSV   1043   \n",
       "57904  A tornado touched down initially near the inte...         CSV   1077   \n",
       "57906  An EF2 tornado touched down in southern Perry ...         CSV  47135   \n",
       "\n",
       "      customers_out        run_start_times lead_time  \n",
       "6               271  [2015-09-05 00:00:00]     [0.0]  \n",
       "7              1397  [2015-09-10 00:00:00]     [0.0]  \n",
       "8               621  [2015-09-04 00:00:00]     [0.0]  \n",
       "9               271  [2015-09-05 00:00:00]     [0.0]  \n",
       "10             1397  [2015-09-10 00:00:00]     [0.0]  \n",
       "...             ...                    ...       ...  \n",
       "57901             0                     []    [-1.0]  \n",
       "57902             0                     []    [-1.0]  \n",
       "57903             0                     []    [-1.0]  \n",
       "57904             0                     []    [-1.0]  \n",
       "57906             0                     []    [-1.0]  \n",
       "\n",
       "[35116 rows x 55 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storm_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_storm_updated.to_csv('leading_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 假设你的 DataFrame 是 df_storm_updated\n",
    "train_df, test_df = train_test_split(df_storm_updated, test_size=0.18, random_state=42)\n",
    "\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "test_df.to_csv('test_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
